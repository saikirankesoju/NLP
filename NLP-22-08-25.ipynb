{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjHnFJV9rvzWrOgKW6/ZPN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikirankesoju/NLP/blob/main/NLP-22-08-25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE0MDzyPEOw8",
        "outputId": "1c60267b-efe3-414d-9d9e-dbc94c38ed36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')\n",
            "\n",
            "First 5 rows:\n",
            "    id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "\n",
            "Dataset after dropping nulls: (7613, 5)\n",
            "\n",
            "Sample sentences from text column:\n",
            "- Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "- Forest fire near La Ronge Sask. Canada\n",
            "- All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
            "- 13,000 people receive #wildfires evacuation orders in California \n",
            "- Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
            "\n",
            "POS Tagging results:\n",
            "\n",
            "Sentence 1: Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "Nouns: ['Deeds', 'earthquake']\n",
            "Verbs: ['Forgive']\n",
            "Adjectives: []\n",
            "--------------------------------------------------\n",
            "Sentence 2: Forest fire near La Ronge Sask. Canada\n",
            "Nouns: ['Forest', 'fire']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "--------------------------------------------------\n",
            "Sentence 3: All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
            "Nouns: ['residents', 'place', 'officers', 'evacuation', 'shelter', 'place', 'orders']\n",
            "Verbs: ['asked', 'shelter', 'notified', 'expected']\n",
            "Adjectives: ['other']\n",
            "--------------------------------------------------\n",
            "Sentence 4: 13,000 people receive #wildfires evacuation orders in California \n",
            "Nouns: ['people', 'wildfires', 'evacuation', 'orders']\n",
            "Verbs: ['receive']\n",
            "Adjectives: []\n",
            "--------------------------------------------------\n",
            "Sentence 5: Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
            "Nouns: ['photo', 'smoke', 'wildfires', 'school']\n",
            "Verbs: ['sent', 'pours']\n",
            "Adjectives: []\n",
            "--------------------------------------------------\n",
            "\n",
            "Text Cleaning Results:\n",
            "\n",
            "Original: My phone number is 9059020516 and my email is saitejaginne@gmail.com\n",
            "Cleaned : My phone number is and my email is\n",
            "------------------------------------------------------------\n",
            "Original: Visit https://example.com for more info!!!\n",
            "Cleaned : Visit for more info\n",
            "------------------------------------------------------------\n",
            "Original: HELLO!!! This is SOOOOO exciting :))\n",
            "Cleaned : HELLO This is SOOOOO exciting\n",
            "------------------------------------------------------------\n",
            "Original: Contact us at info@company.org or call +91 98765-43210\n",
            "Cleaned : Contact us at or call\n",
            "------------------------------------------------------------\n",
            "Original: Python's regex is very useful!!!  #Coding #Fun\n",
            "Cleaned : Python s regex is very useful Coding Fun\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# 1. Load dataset (make sure you've downloaded text-similarity dataset from Kaggle)\n",
        "df = pd.read_csv(\"/content/train.csv\")   # change to the correct file name if different\n",
        "\n",
        "print(\"Columns:\", df.columns)\n",
        "print(\"\\nFirst 5 rows:\\n\", df.head())\n",
        "\n",
        "# Drop null rows\n",
        "df = df.dropna(subset=[\"text\"])\n",
        "print(\"\\nDataset after dropping nulls:\", df.shape)\n",
        "\n",
        "# Extract first 5 sentences\n",
        "sample_texts = df[\"text\"].head(5).tolist()\n",
        "print(\"\\nSample sentences from text column:\")\n",
        "for t in sample_texts:\n",
        "    print(\"-\", t)\n",
        "\n",
        "# ========================\n",
        "# Task 2: POS Tagging with spaCy\n",
        "# ========================\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "print(\"\\nPOS Tagging results:\\n\")\n",
        "for idx, sentence in enumerate(sample_texts, 1):\n",
        "    doc = nlp(sentence)\n",
        "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n",
        "    adjs  = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
        "\n",
        "    print(f\"Sentence {idx}: {sentence}\")\n",
        "    print(\"Nouns:\", nouns)\n",
        "    print(\"Verbs:\", verbs)\n",
        "    print(\"Adjectives:\", adjs)\n",
        "    print(\"-\"*50)\n",
        "\n",
        "# ========================\n",
        "# Q2: Regex Cleaning Task\n",
        "# ========================\n",
        "\n",
        "texts = [\n",
        "    \"My phone number is 9059020516 and my email is saitejaginne@gmail.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!!  #Coding #Fun\"\n",
        "]\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove phone numbers (patterns like 10 digits, or +91 ...)\n",
        "    text = re.sub(r'\\+?\\d[\\d\\-\\s]{8,}\\d', ' ', text)\n",
        "\n",
        "    # Remove emails\n",
        "    text = re.sub(r'\\S+@\\S+\\.\\S+', ' ', text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n",
        "\n",
        "    # Remove special characters except spaces\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s]', ' ', text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "print(\"\\nText Cleaning Results:\\n\")\n",
        "for t in texts:\n",
        "    print(\"Original:\", t)\n",
        "    print(\"Cleaned :\", clean_text(t))\n",
        "    print(\"-\"*60)"
      ]
    }
  ]
}